# LiteLLM Configuration

## Purpose

Configuration templates for running LiteLLM proxy to route requests to multiple LLM providers (Anthropic, OpenAI, etc.) with unified API, cost tracking, and rate limiting.

## Files

### `proxy-config.template.yaml`
Template for LiteLLM proxy configuration. Copy this file and customize for your deployment.

**Key sections:**
- `model_list`: Define model aliases and routing
- `litellm_settings`: Global proxy settings
- `router_settings`: Load balancing and fallback logic
- `general_settings`: Database, logging, API keys

## Setup

1. **Export API keys**:
```bash
export ANTHROPIC_API_KEY="sk-ant-..."
export OPENAI_API_KEY="sk-..."
```

2. **Create config from template**:
```bash
cp config/litellm/proxy-config.template.yaml /tmp/litellm-config.yaml
# Edit /tmp/litellm-config.yaml with your settings
```

3. **Run proxy** (if using LiteLLM):
```bash
litellm --config /tmp/litellm-config.yaml
```

4. **Update backlog config**:
Set `llmOps.gateway.baseURL` in your `backlog.config.json` to point to the proxy.

## Model Routing

The template includes routing rules for:
- **Claude models**: Opus 4.6, Sonnet 3.5, Haiku 3.5
- **OpenAI models**: GPT-4, GPT-4 Turbo, GPT-3.5 Turbo
- **Fallback chains**: Automatic fallback to cheaper models on failure

## Cost Tracking

LiteLLM tracks costs per request. Configure `success_callback` to log to your analytics backend.

## Production Considerations

- **Security**: Never commit API keys. Use environment variables or secret management.
- **Rate limits**: Configure `rpm` and `tpm` per model to avoid provider throttling.
- **Database**: Use PostgreSQL for production (template uses SQLite for dev).
- **Monitoring**: Enable callbacks for observability (e.g., Langfuse, Weights & Biases).

## Related Documentation

- `docs/reference/litellm-proxy-config.md`: Detailed proxy configuration guide
- `docs/runbooks/cost-incident-response.md`: Handle cost overruns


<claude-mem-context>
# Recent Activity

<!-- This section is auto-generated by claude-mem. Edit content outside the tags. -->

### Feb 18, 2026

| ID | Time | T | Title | Read |
|----|------|---|-------|------|
| #7397 | 9:35 PM | ðŸ”µ | Research Agent Investigating LiteLLM Bedrock Configuration | ~330 |
| #7377 | 9:29 PM | ðŸ”µ | LiteLLM proxy configuration documentation found | ~273 |
| #7157 | 3:32 PM | ðŸ”µ | LiteLLM proxy configuration template discovered | ~516 |
| #7138 | 2:40 PM | ðŸŸ£ | Created LiteLLM proxy configuration documentation | ~412 |

### Feb 19, 2026

| ID | Time | T | Title | Read |
|----|------|---|-------|------|
| #7718 | 4:52 PM | ðŸ”µ | LiteLLM Proxy Configuration Architecture | ~335 |
| #7711 | " | ðŸ”µ | LiteLLM Proxy Configuration for Docker | ~332 |
| #7537 | 2:20 PM | âœ… | Redis Cache Enabled in LiteLLM Configuration | ~242 |
| #7535 | " | ðŸ”µ | LiteLLM Cache Configuration Status | ~247 |
| #7488 | 11:39 AM | ðŸ”µ | LiteLLM Proxy Multi-Tier Model Configuration | ~366 |
| #7473 | 11:37 AM | ðŸ”µ | Analyzed existing RAG and service infrastructure | ~339 |
| #7467 | 11:36 AM | ðŸ”µ | LiteLLM Template Configuration Strategy | ~254 |
</claude-mem-context>